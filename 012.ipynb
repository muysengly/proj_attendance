{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "from PyQt5.QtCore import QStringListModel, QTimer\n",
    "from PyQt5.QtWidgets import QMainWindow, QMessageBox, QApplication\n",
    "from PyQt5.QtGui import QImage, QPixmap, QIcon\n",
    "\n",
    "os.system(\"pyuic5 -x gui_v1.ui -o gui_v1.py\")\n",
    "\n",
    "from gui_v1 import Ui_MainWindow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: c:\\Users\\muysengly\\Desktop\\itc_student_attendant\\models\\buffalo_sc\\det_500m.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: c:\\Users\\muysengly\\Desktop\\itc_student_attendant\\models\\buffalo_sc\\w600k_mbf.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "app = QApplication([])\n",
    "\n",
    "fa = FaceAnalysis(\n",
    "    name=\"buffalo_sc\",\n",
    "    root=os.getcwd(),\n",
    "    providers=[\"CPUExecutionProvider\"],\n",
    ")\n",
    "fa.prepare(\n",
    "    ctx_id=-1,\n",
    "    det_thresh=0.5,\n",
    "    det_size=(640, 640),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: need fix.\n",
    "def get_face_embedding(image_path):\n",
    "    \"\"\"Extract face embedding from an image\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not read image: {image_path}\")\n",
    "\n",
    "    faces = fa.get(img)\n",
    "\n",
    "    if len(faces) < 1:\n",
    "        print(f'Image: \"{image_path}\"')\n",
    "        raise ValueError(\"No faces detected in the image\")\n",
    "        # SOLUTION: return none or remove image\n",
    "    if len(faces) > 1:\n",
    "        print(\"Warning: Multiple faces detected. Using first detected face\")\n",
    "        print(f'Image: \"{image_path}\"')\n",
    "        # SOLUTION: crop or fix image\n",
    "\n",
    "    return faces[0].embedding\n",
    "\n",
    "\n",
    "# NOTE: need fix the threshold\n",
    "def compare_faces_cosine(emb1, emb2):\n",
    "    \"\"\"Compare two embeddings using cosine similarity\"\"\"\n",
    "    similarity = np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def list_folders(directory, pattern=None):\n",
    "    if pattern is not None:\n",
    "        return [f for f in os.listdir(directory) if os.path.isdir(os.path.join(directory, f)) and re.search(pattern, f)]\n",
    "    else:\n",
    "        return [f for f in os.listdir(directory) if os.path.isdir(os.path.join(directory, f))]\n",
    "\n",
    "\n",
    "def list_files(directory, pattern=None):\n",
    "    if pattern is None:\n",
    "        return [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "    else:\n",
    "        return [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f)) and re.search(pattern, f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = list_folders(\"./data\")\n",
    "dirs_files = []\n",
    "for dir in dirs:\n",
    "    files = list_files(f\"./data/{dir}/\")\n",
    "    dirs_files.append([dir, files])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dirs_embs = []\n",
    "for dir, files in dirs_files:\n",
    "    tmp = []\n",
    "    for file in files:\n",
    "        emb = get_face_embedding(f\"./data/{dir}/{file}\")\n",
    "        tmp.append(emb)\n",
    "    all_dirs_embs.append([dir, tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "THRESHOLD = 0.70\n",
    "\n",
    "\n",
    "class Window(Ui_MainWindow, QMainWindow):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.setupUi(self)\n",
    "        # self.setWindowFlags(self.windowFlags() | QtCore.Qt.WindowStaysOnTopHint)\n",
    "\n",
    "        # set win title\n",
    "        self.setWindowTitle(\"ITC's Attendance System\")\n",
    "\n",
    "        # set win icon\n",
    "        self.setWindowIcon(QIcon(\"./logo/itc_logo.png\"))\n",
    "\n",
    "        # Timer for real-time updates\n",
    "        self.timer = QTimer(self)\n",
    "\n",
    "        self.timer.timeout.connect(self.update)\n",
    "        # self.timer.start(16) # 60 FPS\n",
    "        self.timer.start(33)  # 30 FPS\n",
    "\n",
    "        self.remain_dirs_embs = all_dirs_embs.copy()\n",
    "\n",
    "        self.data_init = [self.remain_dirs_embs[i][0] for i in range(len(self.remain_dirs_embs))]\n",
    "        self.model_init = QStringListModel()\n",
    "        self.model_init.setStringList(self.data_init)\n",
    "        self.listView_init.setModel(self.model_init)\n",
    "\n",
    "        self.data_attd = []\n",
    "        self.model_attd = QStringListModel()\n",
    "        self.model_attd.setStringList(self.data_attd)\n",
    "        self.listView_attd.setModel(self.model_attd)\n",
    "\n",
    "        self.WIDTH = self.label_camera.width()\n",
    "        self.HEIGHT = self.label_camera.height()\n",
    "\n",
    "        self.col_data = []\n",
    "\n",
    "        self.show()\n",
    "\n",
    "    def paintEvent(self, event):\n",
    "\n",
    "        # read frame from camera\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # detect faces\n",
    "        faces = fa.get(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        if len(faces) > 0:\n",
    "            for face in faces:\n",
    "                box = face.bbox.astype(int)\n",
    "\n",
    "                # score for all names\n",
    "                tmp1_score_all = []\n",
    "                for name, embs in all_dirs_embs:\n",
    "                    tmp1_high_score = 0\n",
    "                    for emb in embs:\n",
    "                        sim_score = compare_faces_cosine(face.embedding, emb)\n",
    "                        if sim_score > tmp1_high_score:\n",
    "                            tmp1_high_score = sim_score\n",
    "                    tmp1_score_all.append(tmp1_high_score)\n",
    "\n",
    "                # score for remaining names\n",
    "                tmp_score_remain = []\n",
    "                for name, embs in self.remain_dirs_embs:\n",
    "                    tmp_high_score = 0\n",
    "                    for emb in embs:\n",
    "                        sim_score = compare_faces_cosine(face.embedding, emb)\n",
    "                        if sim_score > tmp_high_score:\n",
    "                            tmp_high_score = sim_score\n",
    "                    tmp_score_remain.append(tmp_high_score)\n",
    "\n",
    "                # for known faces with high score\n",
    "                if np.max(np.array(tmp_score_remain)) > THRESHOLD:\n",
    "\n",
    "                    # attendant data\n",
    "                    self.col_data.append(f\"{self.remain_dirs_embs[np.argmax(np.array(tmp_score_remain))][0]}, {date.today().strftime(\"%Y-%m-%d\")}, {time.strftime(\"%H:%M:%S\")}\",)\n",
    "\n",
    "                    self.data_attd.append(self.remain_dirs_embs[np.argmax(np.array(tmp_score_remain))][0])\n",
    "                    self.model_attd.setStringList(self.data_attd)\n",
    "                    self.listView_attd.setModel(self.model_attd)\n",
    "\n",
    "                    self.remain_dirs_embs.pop(np.argmax(np.array(tmp_score_remain)))\n",
    "\n",
    "                    self.data_init = [self.remain_dirs_embs[i][0] for i in range(len(self.remain_dirs_embs))]\n",
    "                    self.model_init.setStringList(self.data_init)\n",
    "                    self.listView_init.setModel(self.model_init)\n",
    "\n",
    "                # for attended faces\n",
    "                elif np.max(np.array(tmp1_score_all)) > THRESHOLD:\n",
    "\n",
    "                    if len(self.data_attd) > 0:\n",
    "                        for i in range(len(self.data_attd)):\n",
    "                            if self.data_attd[i] == all_dirs_embs[np.argmax(np.array(tmp1_score_all))][0]:\n",
    "                                cv2.rectangle(\n",
    "                                    img=frame,\n",
    "                                    pt1=(box[0], box[1]),\n",
    "                                    pt2=(box[2], box[3]),\n",
    "                                    color=(0, 255, 0),\n",
    "                                    thickness=2,\n",
    "                                )\n",
    "                                cv2.putText(\n",
    "                                    img=frame,\n",
    "                                    text=f\"{all_dirs_embs[np.argmax(np.array(tmp1_score_all))][0]} {100*np.max(np.array(tmp1_score_all)):.0f}%\",\n",
    "                                    org=(box[0], box[1] - 10),\n",
    "                                    fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                    fontScale=0.5,\n",
    "                                    color=(0, 255, 0),\n",
    "                                    thickness=2,\n",
    "                                )\n",
    "                                cv2.putText(\n",
    "                                    img=frame,\n",
    "                                    text=\"Attended\",\n",
    "                                    org=(box[0], box[3] + 20),\n",
    "                                    fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                    fontScale=0.5,\n",
    "                                    color=(0, 255, 0),\n",
    "                                    thickness=2,\n",
    "                                )\n",
    "\n",
    "                # for unknown faces\n",
    "                else:\n",
    "                    cv2.rectangle(\n",
    "                        img=frame,\n",
    "                        pt1=(box[0], box[1]),\n",
    "                        pt2=(box[2], box[3]),\n",
    "                        color=(0, 0, 255),\n",
    "                        thickness=2,\n",
    "                    )\n",
    "                    cv2.putText(\n",
    "                        img=frame,\n",
    "                        text=f\"{all_dirs_embs[np.argmax(np.array(tmp1_score_all))][0]} {100*np.max(np.array(tmp1_score_all)):.0f}%\",\n",
    "                        org=(box[0], box[1] - 10),\n",
    "                        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        fontScale=0.5,\n",
    "                        color=(0, 0, 255),\n",
    "                        thickness=2,\n",
    "                    )\n",
    "                    cv2.putText(\n",
    "                        img=frame,\n",
    "                        text=\"Unknown\",\n",
    "                        org=(box[0], box[3] + 20),\n",
    "                        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        fontScale=0.5,\n",
    "                        color=(0, 0, 255),\n",
    "                        thickness=2,\n",
    "                    )\n",
    "\n",
    "        # display camera\n",
    "        tmp_screen = np.array(cv2.resize(frame, dsize=(self.WIDTH, self.HEIGHT), interpolation=cv2.INTER_CUBIC))\n",
    "        image = cv2.cvtColor(tmp_screen, cv2.COLOR_BGR2RGB)\n",
    "        q_image = QImage(image.data, self.WIDTH, self.HEIGHT, QImage.Format.Format_RGB888)\n",
    "        q_pixmap = QPixmap.fromImage(q_image)\n",
    "        self.label_camera.setPixmap(q_pixmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win = Window()\n",
    "\n",
    "\n",
    "def f_save():\n",
    "    # save data to csv file\n",
    "    with open(f\"attendance/attendance_{date.today().strftime(\"%Y_%m_%d\")}_{time.strftime(\"%H_%M_%S\")}.csv\", \"w\") as f:\n",
    "        for item in win.col_data:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    # show message box\n",
    "    msg = QMessageBox()\n",
    "    msg.setWindowIcon(QIcon(\"./itc_logo.png\"))\n",
    "    msg.setIcon(QMessageBox.Icon.Information)\n",
    "    msg.setText(\"Data saved successfully\")\n",
    "    msg.setWindowTitle(\"Success\")\n",
    "    msg.setStandardButtons(QMessageBox.StandardButton.Ok)\n",
    "    msg.exec_()\n",
    "\n",
    "\n",
    "def f_reset():\n",
    "\n",
    "    win.remain_dirs_embs = all_dirs_embs.copy()\n",
    "\n",
    "    win.col_data = []\n",
    "\n",
    "    win.data_attd = []\n",
    "    win.model_attd = QStringListModel()\n",
    "    win.model_attd.setStringList(win.data_attd)\n",
    "    win.listView_attd.setModel(win.model_attd)\n",
    "\n",
    "    win.data_init = [win.remain_dirs_embs[i][0] for i in range(len(win.remain_dirs_embs))]\n",
    "    win.model_init = QStringListModel()\n",
    "    win.model_init.setStringList(win.data_init)\n",
    "    win.listView_init.setModel(win.model_init)\n",
    "\n",
    "\n",
    "# connect buttons to functions\n",
    "win.pushButton_save.clicked.connect(f_save)\n",
    "win.pushButton_reset.clicked.connect(f_reset)\n",
    "\n",
    "# set image to win.label_logo_itc\n",
    "logo_itc = cv2.imread(\"./logo/itc_logo.png\")\n",
    "logo_itc = cv2.cvtColor(logo_itc, cv2.COLOR_BGR2RGB)\n",
    "logo_itc = cv2.resize(logo_itc, (win.label_logo_itc.width(), win.label_logo_itc.height()))\n",
    "q_logo_itc = QImage(logo_itc.data, logo_itc.shape[1], logo_itc.shape[0], QImage.Format.Format_RGB888)\n",
    "q_pixmap_logo_itc = QPixmap.fromImage(q_logo_itc)\n",
    "win.label_logo_itc.setPixmap(q_pixmap_logo_itc)\n",
    "win.label_logo_itc.setScaledContents(True)\n",
    "\n",
    "\n",
    "# set image to win.label_logo_gtr\n",
    "logo_gtr = cv2.imread(\"./logo/gtr_logo.jpg\")\n",
    "logo_gtr = cv2.cvtColor(logo_gtr, cv2.COLOR_BGR2RGB)\n",
    "logo_gtr = cv2.resize(logo_gtr, (win.label_logo_gtr.width(), win.label_logo_gtr.height()))\n",
    "q_logo_gtr = QImage(logo_gtr.data, logo_gtr.shape[1], logo_gtr.shape[0], QImage.Format.Format_RGB888)\n",
    "q_pixmap_logo_gtr = QPixmap.fromImage(q_logo_gtr)\n",
    "win.label_logo_gtr.setPixmap(q_pixmap_logo_gtr)\n",
    "win.label_logo_gtr.setScaledContents(True)\n",
    "\n",
    "app.exec()\n",
    "\n",
    "app.quit()\n",
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
